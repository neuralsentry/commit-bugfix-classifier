{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "import itertools\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import clang.cindex\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from git import Repo, Commit, Diff\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/devign_2023_functions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "non-bugfix    12945\n",
       "bugfix         3384\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = clang.cindex.Index.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/devign.csv\")\n",
    "df = df[df[\"is_merge\"] == \"False\"]\n",
    "df = df[~df[\"labels\"].str.contains(\"outside-threshold\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/output.csv\")\n",
    "df = df[df[\"label\"] == \"non-bugfix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(15000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [urlparse(url) for url in df[\"remote_url\"]]\n",
    "paths = [\n",
    "    f\"data/repositories/{url.netloc}/{'/'.join(url.path.split('/')[1:3])}\"\n",
    "    for url in urls\n",
    "]\n",
    "df[\"path\"] = paths\n",
    "\n",
    "repos = {}\n",
    "commits: list[Commit] = []\n",
    "for i, row in df.iterrows():\n",
    "    path = row[\"path\"]\n",
    "    if repos.get(path) is None:\n",
    "        repos[path] = Repo(path)\n",
    "\n",
    "    repo = repos[path]\n",
    "    commits.append(repo.commit(row[\"sha\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11930/11930 [21:24<00:00,  9.29it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_hunk_headers_function(diff: Diff):\n",
    "    # given a diff, read each line containing a hunk header \"@@ -a,b +c,d @@ <function>\"\n",
    "    # and return a list of functions\n",
    "    # if the hunk header has no function, don't include it\n",
    "\n",
    "    # read the diff\n",
    "    diff_text = diff.diff.decode(\"latin-1\")\n",
    "    # split the diff into lines\n",
    "    diff_lines = diff_text.split(\"\\n\")\n",
    "\n",
    "    # regex to match hunk header\n",
    "    hunk_header_regex = re.compile(r\"^@@ -\\d+,\\d+ \\+\\d+,\\d+ @@\")\n",
    "\n",
    "    # regex to match function name\n",
    "    function_name_regex = re.compile(r\"@@ -\\d+,\\d+ \\+\\d+,\\d+ @@ (.+)\")\n",
    "\n",
    "    # list of functions\n",
    "    functions = []\n",
    "\n",
    "    # iterate over each line\n",
    "    for line in diff_lines:\n",
    "        # if the line matches the hunk header regex\n",
    "        if hunk_header_regex.match(line):\n",
    "            # try to match the function name regex\n",
    "            match = function_name_regex.match(line)\n",
    "            # if the function name regex matches\n",
    "            if match:\n",
    "                # append the function name to the list of functions\n",
    "                functions.append(match.group(1))\n",
    "\n",
    "    # return the list of functions\n",
    "    return functions\n",
    "\n",
    "\n",
    "def find_function(node, function_name):\n",
    "    if (\n",
    "        node.kind == clang.cindex.CursorKind.FUNCTION_DECL\n",
    "        and node.spelling == function_name\n",
    "    ):\n",
    "        return node\n",
    "    for child in node.get_children():\n",
    "        result = find_function(child, function_name)\n",
    "        if result is not None:\n",
    "            return result\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_function_source(file_path, function):\n",
    "    # Get the starting and ending line numbers of the function\n",
    "    start_line = function.extent.start.line\n",
    "    end_line = function.extent.end.line\n",
    "\n",
    "    # with open(file_path, \"r\") as file:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Extract the function's source code\n",
    "    function_source = \"\".join(lines[start_line - 1 : end_line])\n",
    "    return function_source\n",
    "\n",
    "\n",
    "def batch(iterable, size):\n",
    "    sourceiter = iter(iterable)\n",
    "    while True:\n",
    "        batchiter = itertools.islice(sourceiter, size)\n",
    "        yield list(batchiter)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "batch = []\n",
    "header = True\n",
    "for i, commit in enumerate(tqdm(commits[3070:])):\n",
    "    batch.append(commit)\n",
    "\n",
    "    if len(batch) == BATCH_SIZE or (i + 1 == len(commits[3070:]) and len(batch) > 0):\n",
    "        results = []\n",
    "        for i, commit in enumerate(batch):\n",
    "            result = {}\n",
    "            result[\"sha\"] = commit.hexsha\n",
    "            result[\"remote_url\"] = commit.repo.remotes[0].url\n",
    "            result[\"label\"] = df.iloc[i][\"label\"]\n",
    "            result[\"commit_msg\"] = commit.message\n",
    "\n",
    "            parent_commit = commit.parents[0]\n",
    "            diff_items = parent_commit.diff(commit, create_patch=True)\n",
    "\n",
    "            # diff filter conditions\n",
    "            # 1. modified files\n",
    "            # 2. .c extension\n",
    "            # 3. only 1 modified .c file\n",
    "            diffs: list[Diff] = [\n",
    "                diff\n",
    "                for diff in diff_items.iter_change_type(\"M\")\n",
    "                if diff.a_path.endswith(\".c\")\n",
    "            ]\n",
    "\n",
    "            if not len(diffs) == 1:\n",
    "                continue\n",
    "\n",
    "            diff = diffs[0]\n",
    "\n",
    "            functions = get_hunk_headers_function(diff)\n",
    "            # diff functions filter conditions\n",
    "            # 1. Only 1 function is modified\n",
    "            # if not len(functions) == 1:\n",
    "            #     continue\n",
    "\n",
    "            if len(functions) == 0:\n",
    "                continue\n",
    "            if len(functions) > 1:\n",
    "                continue\n",
    "\n",
    "            # function_names = [re.search(r\"(\\w+)\\(\", function) for function in functions]\n",
    "            # function_names = [\n",
    "            #     function_name.group(1)\n",
    "            #     for function_name in function_names\n",
    "            #     if function_name is not None\n",
    "            # ]\n",
    "\n",
    "            function_name = re.search(r\"(\\w+)\\(\", functions[0])\n",
    "\n",
    "            if function_name is None:\n",
    "                continue\n",
    "\n",
    "            function_name = function_name.group(1)\n",
    "\n",
    "            file_path = diff.a_path\n",
    "            try:\n",
    "                code = commit.repo.git.show(f\"{commit.hexsha}:{file_path}\")\n",
    "            except:\n",
    "                continue\n",
    "            temp_file = \"data/temp.c\"\n",
    "\n",
    "            with open(temp_file, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(code)\n",
    "\n",
    "            translation_unit = index.parse(temp_file)\n",
    "\n",
    "            c_func = find_function(translation_unit.cursor, function_name)\n",
    "\n",
    "            if c_func is None:\n",
    "                continue\n",
    "\n",
    "            result[\"function\"] = get_function_source(temp_file, c_func)\n",
    "\n",
    "            # functions = {}\n",
    "            # for function_name in function_names:\n",
    "            #     c_func = find_function(translation_unit.cursor, function_name)\n",
    "            #     if c_func is None:\n",
    "            #         continue\n",
    "\n",
    "            #     functions[function_name] = get_function_source(temp_file, c_func)\n",
    "\n",
    "            # if len(functions) == 0:\n",
    "            #     continue\n",
    "\n",
    "            # result[\"functions\"] = functions\n",
    "\n",
    "            results.append(result)\n",
    "\n",
    "        if len(results) > 0:\n",
    "            results_df = pd.DataFrame(results)\n",
    "            results_df[\"num_functions\"] = results_df[\"functions\"].apply(\n",
    "                lambda functions: len(functions)\n",
    "            )\n",
    "            results_df.to_json(\n",
    "                \"data/function_sources.jsonl\", mode=\"a\", lines=True, orient=\"records\"\n",
    "            )\n",
    "            results_df.to_csv(\n",
    "                \"data/function_sources.csv\", mode=\"a\", index=False, header=header\n",
    "            )\n",
    "            header = False\n",
    "\n",
    "        batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df[\"num_functions\"] = results_df[\"functions\"].apply(\n",
    "    lambda functions: len(functions)\n",
    ")\n",
    "results_df[\"num_functions\"].value_counts()\n",
    "results_df.to_json(\"data/function_sources.json\", orient=\"records\")\n",
    "\n",
    "with open(\"data/function_sources.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "with open(\"data/function_sources.json\", \"w\") as file:\n",
    "    json.dump(data, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = pd.read_csv(\"data/function_sources.csv\")\n",
    "functions.iloc[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
